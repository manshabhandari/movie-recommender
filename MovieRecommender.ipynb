{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ypgs_BIt0gUF"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from typing import Tuple\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Embedding, Flatten, Concatenate, Dense, Lambda\n",
        "from urllib.request import urlretrieve\n",
        "import zipfile"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v3oSCnEu0GYA",
        "outputId": "5b79fc55-8e68-4d6c-a6f1-031ffa573b06"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Done. Dataset contains:\n",
            "b'943 users\\n1682 items\\n100000 ratings\\n'\n"
          ]
        }
      ],
      "source": [
        "urlretrieve(\"http://files.grouplens.org/datasets/movielens/ml-100k.zip\", \"movielens.zip\")\n",
        "zip_ref = zipfile.ZipFile('movielens.zip', \"r\")\n",
        "zip_ref.extractall()\n",
        "\n",
        "print(\"Done. Dataset contains:\")\n",
        "print(zip_ref.read('ml-100k/u.info'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cQAhXU0X0MGr"
      },
      "outputs": [],
      "source": [
        "# Load each data set (users, movies, and ratings).\n",
        "users_cols = ['user_id', 'age', 'sex', 'occupation', 'zip_code']\n",
        "users = pd.read_csv('ml-100k/u.user', sep='|', names=users_cols, encoding='latin-1')\n",
        "ratings_cols = ['user_id', 'movie_id', 'rating', 'unix_timestamp']\n",
        "ratings = pd.read_csv('ml-100k/u.data', sep='\\t', names=ratings_cols, encoding='latin-1')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y0zLTka30ObF"
      },
      "outputs": [],
      "source": [
        "# The movies file contains a binary feature for each genre.\n",
        "genre_cols = [\n",
        "   \"genre_unknown\", \"Action\", \"Adventure\", \"Animation\", \"Children\", \"Comedy\",\n",
        "   \"Crime\", \"Documentary\", \"Drama\", \"Fantasy\", \"Film-Noir\", \"Horror\",\n",
        "   \"Musical\", \"Mystery\", \"Romance\", \"Sci-Fi\", \"Thriller\", \"War\", \"Western\"\n",
        "]\n",
        "\n",
        "movies_cols = [\n",
        "   'movie_id', 'title', 'release_date', \"video_release_date\", \"imdb_url\"\n",
        "] + genre_cols\n",
        "\n",
        "movies = pd.read_csv('ml-100k/u.item', sep='|', names=movies_cols, encoding='latin-1')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RB4Vh6lOcXzV",
        "outputId": "2333e2cd-eb57-44ff-e381-154415611a8b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Number of users: 943\n",
            "Number of movies: 1682\n",
            "Number of ratings: 100000\n"
          ]
        }
      ],
      "source": [
        "#Basic statistics about the data\n",
        "\n",
        "print(f\"\\nNumber of users: {users['user_id'].nunique()}\")\n",
        "print(f\"Number of movies: {movies['movie_id'].nunique()}\")\n",
        "print(f\"Number of ratings: {ratings.shape[0]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d1SfSsttyeVr"
      },
      "source": [
        "Implementing the unweighted regularized Matrix Factorization Collaborative Filtering algorithm to build a recommendation system."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5ms1ugPxyfuW"
      },
      "outputs": [],
      "source": [
        "# Loading the ratings\n",
        "ratings_cols = ['user_id', 'movie_id', 'rating', 'unix_timestamp']\n",
        "ratings = pd.read_csv('ml-100k/u.data', sep='\\t', names=ratings_cols, encoding='latin-1')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RFtmSfOC7LZm"
      },
      "outputs": [],
      "source": [
        "# Mapping the user and movie IDs to continuous indices\n",
        "user_map = {id: idx for idx, id in enumerate(ratings['user_id'].unique())}\n",
        "movie_map = {id: idx for idx, id in enumerate(ratings['movie_id'].unique())}\n",
        "\n",
        "ratings['user_idx'] = ratings['user_id'].map(user_map)\n",
        "ratings['movie_idx'] = ratings['movie_id'].map(movie_map)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wJPK_ZvF7L_s"
      },
      "outputs": [],
      "source": [
        "# Preparing the training data\n",
        "num_users = len(user_map)\n",
        "num_movies = len(movie_map)\n",
        "num_features = 15\n",
        "lr = 0.01\n",
        "reg = 0.1\n",
        "epochs = 20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uepmnPXO7O3F"
      },
      "outputs": [],
      "source": [
        "# Initialising the latent features\n",
        "np.random.seed(0)\n",
        "P = np.random.normal(scale=1./num_features, size=(num_users, num_features))\n",
        "Q = np.random.normal(scale=1./num_features, size=(num_movies, num_features))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kcmzTEo17RMU",
        "outputId": "1ed6457d-ba70-4dfa-8a55-b376eff5665e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1, MSE: 6.8464\n",
            "Epoch 2, MSE: 1.4525\n",
            "Epoch 3, MSE: 1.0556\n",
            "Epoch 4, MSE: 0.9610\n",
            "Epoch 5, MSE: 0.9218\n",
            "Epoch 6, MSE: 0.8987\n",
            "Epoch 7, MSE: 0.8814\n",
            "Epoch 8, MSE: 0.8666\n",
            "Epoch 9, MSE: 0.8532\n",
            "Epoch 10, MSE: 0.8410\n",
            "Epoch 11, MSE: 0.8300\n",
            "Epoch 12, MSE: 0.8203\n",
            "Epoch 13, MSE: 0.8116\n",
            "Epoch 14, MSE: 0.8036\n",
            "Epoch 15, MSE: 0.7961\n",
            "Epoch 16, MSE: 0.7889\n",
            "Epoch 17, MSE: 0.7819\n",
            "Epoch 18, MSE: 0.7750\n",
            "Epoch 19, MSE: 0.7681\n",
            "Epoch 20, MSE: 0.7613\n"
          ]
        }
      ],
      "source": [
        "# Stochastic Gradient Descent\n",
        "for epoch in range(epochs):\n",
        "    for row in ratings.itertuples():\n",
        "        u = row.user_idx\n",
        "        m = row.movie_idx\n",
        "        r = row.rating\n",
        "\n",
        "        pred = np.dot(P[u], Q[m])\n",
        "        pred = np.clip(pred, 1, 5)\n",
        "\n",
        "        err = r - pred\n",
        "\n",
        "        P[u] += lr * (err * Q[m] - reg * P[u])\n",
        "        Q[m] += lr * (err * P[u] - reg * Q[m])\n",
        "\n",
        "    mse = np.mean([\n",
        "        (row.rating - np.clip(np.dot(P[row.user_idx], Q[row.movie_idx]), 1, 5)) ** 2\n",
        "        for row in ratings.itertuples()\n",
        "    ])\n",
        "    print(f\"Epoch {epoch+1}, MSE: {mse:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DH0IZ9XX8OQo"
      },
      "source": [
        "Implementing the algorithm:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sez_QVk78Q_Q"
      },
      "outputs": [],
      "source": [
        "def recommend_movies(user_id, top_n=5):\n",
        "    u_idx = user_map[user_id]\n",
        "    scores = np.dot(P[u_idx], Q.T)\n",
        "    scores = np.clip(scores, 1, 5)\n",
        "\n",
        "    watched = ratings[ratings['user_id'] == user_id]['movie_id'].tolist()\n",
        "    unwatched_scores = [(mid, score) for mid, score in zip(movie_map.keys(), scores) if mid not in watched]\n",
        "\n",
        "    top_movies = sorted(unwatched_scores, key=lambda x: -x[1])[:top_n]\n",
        "\n",
        "    recommended_titles = [\n",
        "        (movies[movies['movie_id'] == movie_id]['title'].values[0], float(round(score, 2)))\n",
        "        for movie_id, score in top_movies\n",
        "    ]\n",
        "\n",
        "    return recommended_titles"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hyv_3jCX8UvP",
        "outputId": "a1b11640-75c4-47b8-9a7d-96f365a2b148"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('Pather Panchali (1955)', 4.81),\n",
              " ('Wrong Trousers, The (1993)', 4.67),\n",
              " (\"Schindler's List (1993)\", 4.62),\n",
              " ('Rear Window (1954)', 4.53),\n",
              " ('Close Shave, A (1995)', 4.5)]"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "recommend_movies(284)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LlljXVwM-wG_"
      },
      "source": [
        "Building a deep neural network using Tensorflow to implement a recommendation system using the same dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5z96j4oBHMWi"
      },
      "outputs": [],
      "source": [
        "# Encoding the user and movie IDs as categorical indices\n",
        "ratings['user'] = ratings['user_id'].map(user_map)\n",
        "ratings['movie'] = ratings['movie_id'].map(movie_map)\n",
        "\n",
        "X = ratings[['user', 'movie']].values\n",
        "y = ratings['rating'].values\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "id": "4O2sd8UMHyDM",
        "outputId": "765b3748-e511-464f-d54a-fee779f47768"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"functional\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ input_layer_1       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ embedding           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)     │     <span style=\"color: #00af00; text-decoration-color: #00af00\">18,860</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ embedding_1         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)     │     <span style=\"color: #00af00; text-decoration-color: #00af00\">33,640</span> │ input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ embedding_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ flatten[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ flatten_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,624</span> │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │ dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ input_layer_1       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ embedding           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m20\u001b[0m)     │     \u001b[38;5;34m18,860\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ embedding_1         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m20\u001b[0m)     │     \u001b[38;5;34m33,640\u001b[0m │ input_layer_1[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ embedding_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ flatten[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ flatten_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │      \u001b[38;5;34m2,624\u001b[0m │ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │      \u001b[38;5;34m2,080\u001b[0m │ dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │         \u001b[38;5;34m33\u001b[0m │ dense_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">57,237</span> (223.58 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m57,237\u001b[0m (223.58 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">57,237</span> (223.58 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m57,237\u001b[0m (223.58 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "num_users = len(user_map)\n",
        "num_movies = len(movie_map)\n",
        "embedding_dim = 20\n",
        "\n",
        "# User input\n",
        "user_input = Input(shape = (1,))\n",
        "user_embedding = Embedding(input_dim = num_users, output_dim = embedding_dim)(user_input)\n",
        "user_vec = Flatten()(user_embedding)\n",
        "\n",
        "# Movie input\n",
        "movie_input = Input(shape = (1,))\n",
        "movie_embedding = Embedding(input_dim = num_movies, output_dim = embedding_dim)(movie_input)\n",
        "movie_vec = Flatten()(movie_embedding)\n",
        "\n",
        "# Concatenating and feeding to the MLP\n",
        "concat = Concatenate()([user_vec, movie_vec])\n",
        "dense = Dense(64, activation = 'relu')(concat)\n",
        "dense = Dense(32, activation = 'relu')(dense)\n",
        "output = Dense(1, activation = 'linear')(dense)\n",
        "\n",
        "model = Model([user_input, movie_input], output)\n",
        "model.compile(optimizer = 'adam', loss = 'mse', metrics = ['mae'])\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GiLl8lQHH2SM",
        "outputId": "36499c7a-0368-43bc-879e-ab2b83414d33"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 5.5178 - mae: 1.8485 - val_loss: 0.9061 - val_mae: 0.7497\n",
            "Epoch 2/10\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.8859 - mae: 0.7438 - val_loss: 0.8954 - val_mae: 0.7476\n",
            "Epoch 3/10\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.8622 - mae: 0.7344 - val_loss: 0.8917 - val_mae: 0.7467\n",
            "Epoch 4/10\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.8620 - mae: 0.7323 - val_loss: 0.8900 - val_mae: 0.7505\n",
            "Epoch 5/10\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.8518 - mae: 0.7292 - val_loss: 0.8818 - val_mae: 0.7431\n",
            "Epoch 6/10\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.8253 - mae: 0.7165 - val_loss: 0.8672 - val_mae: 0.7359\n",
            "Epoch 7/10\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.8156 - mae: 0.7116 - val_loss: 0.8670 - val_mae: 0.7367\n",
            "Epoch 8/10\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.7966 - mae: 0.7012 - val_loss: 0.8621 - val_mae: 0.7360\n",
            "Epoch 9/10\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.7777 - mae: 0.6930 - val_loss: 0.8596 - val_mae: 0.7326\n",
            "Epoch 10/10\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.7575 - mae: 0.6819 - val_loss: 0.8615 - val_mae: 0.7353\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(\n",
        "    [X_train[:, 0], X_train[:, 1]],\n",
        "    y_train,\n",
        "    batch_size=256,\n",
        "    epochs=10,\n",
        "    validation_data = ([X_test[:, 0], X_test[:, 1]], y_test)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y_kf76XXHQGL"
      },
      "outputs": [],
      "source": [
        "def deep_recommend_movies(user_id, top_n=5):\n",
        "    user_idx = user_map[user_id]\n",
        "    watched = ratings[ratings['user_id'] == user_id]['movie_id'].tolist()\n",
        "\n",
        "    all_movie_ids = list(movie_map.keys())\n",
        "    unwatched = [m for m in all_movie_ids if m not in watched]\n",
        "\n",
        "    movie_indices = [movie_map[m] for m in unwatched]\n",
        "    user_indices = [user_idx] * len(movie_indices)\n",
        "\n",
        "    predictions = model.predict([np.array(user_indices), np.array(movie_indices)], verbose=0)\n",
        "    top_indices = np.argsort(predictions.flatten())[::-1][:top_n]\n",
        "    top_movie_ids = [unwatched[i] for i in top_indices]\n",
        "\n",
        "    return [(movies[movies['movie_id'] == mid]['title'].values[0], round(float(predictions[i][0]), 2))\n",
        "            for i, mid in zip(top_indices, top_movie_ids)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "90QA6pfjHSH2",
        "outputId": "57ebce42-3a83-4811-e853-81582a272a82"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('Pather Panchali (1955)', 4.96),\n",
              " ('Santa with Muscles (1996)', 4.95),\n",
              " ('Whole Wide World, The (1996)', 4.84),\n",
              " ('Casablanca (1942)', 4.8),\n",
              " ('Anna (1996)', 4.77)]"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "deep_recommend_movies(345)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MoQQmf3ZI9I4"
      },
      "source": [
        "**My Design Choices**\n",
        "\n",
        "1. **Embeddings for Users and Movies**: Instead of one-hot encoding user and movie IDs (which would result in sparse high-dimensional vectors), I used embedding layers to learn dense vector representations:\n",
        "\n",
        "  * User Embedding Layer: `Embedding(input_dim = num_users, output_dim = 20)`\n",
        "\n",
        "  * Movie Embedding Layer: `Embedding(input_dim = num_movies, output_dim = 20)`\n",
        "\n",
        "  I did this because embeddings allow the model to learn latent features about users (preference for genres) and movies (appeal to certain audiences) directly from the data. I chose a dimensionality of 20, which balances expressive power with model simplicity. Larger embedding sizes can capture more detail but risk overfitting on small datasets.\n",
        "\n",
        "2. **Hidden Layers (Multi-Layer Perceptron)**: After concatenating the user and movie embeddings, I passed the result through two fully connected (dense) layers:\n",
        "\n",
        "  `dense = Dense(64, activation = 'relu')(concat)`\n",
        "\n",
        "  `dense = Dense(32, activation = 'relu')(dense)`\n",
        "\n",
        "  I used two layers to introduce non-linearity and enable the model to learn more complex interactions between users and movies. The first layer has 64 neurons, and the second has 32, which follows a common architecture design pattern of reducing dimensions progressively. I used ReLU activation because it is used for its computational efficiency and its ability to avoid vanishing gradients compared to sigmoid or tanh.\n",
        "\n",
        "3. **Output Layer**: `output = Dense(1, activation = 'linear')(dense)`\n",
        "  \n",
        "  The model outputs a single predicted rating as a continuous value.\n",
        "  \n",
        "  I used a linear activation so the model is not artificially constrained during learning, which means it can output any real number, which is useful during early training. If needed, predictions can be clipped to the [1, 5] range later, but the linear activation gives the network flexibility to explore.\n",
        "\n",
        "4. **Loss Function and Optimization**: `model.compile(optimizer = 'adam', loss = 'mse', metrics = ['mae'])`\n",
        "\n",
        "  I used Mean Squared Error (MSE) as the loss function because we are predicting real-valued ratings (regression). MSE penalizes larger errors more strongly, which encourages the model to make precise predictions. I also included Mean Absolute Error (MAE) as a metric to track performance in a more interpretable way (average absolute deviation from actual ratings). Something new I learnt is the Adam optimizer which is a strong default choice for deep learning models, combining momentum and adaptive learning rates for faster convergence.\n",
        "\n",
        "5. **Train-Test Split and Evaluation**: I split the data into 80% training and 20% test to ensure the model can generalize and avoid overfitting. I also monitor validation loss during training to verify that learning is progressing as expected."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wo68z6kUDl-A"
      },
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
